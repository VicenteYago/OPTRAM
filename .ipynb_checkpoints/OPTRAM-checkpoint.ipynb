{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d7f8dec",
   "metadata": {},
   "source": [
    "![walnut-gulch](./img/WG_nologo2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8829ffa2",
   "metadata": {},
   "source": [
    "Walnut Gulch Experimental Watershed in southeastern Arizona by Sentinel-2. Credits: Sentinel-hub (https://www.sentinel-hub.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0b8513",
   "metadata": {},
   "source": [
    "# Implementation of Optical Trapezoid Model (OPTRAM) with Sentinel 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a732477f",
   "metadata": {},
   "source": [
    "Author : Jose Vicente Yago Martinez - jvyagomartinez@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c981c4ba",
   "metadata": {},
   "source": [
    "The Optical Trapezoid Model (OPTRAM) was developed to overcome the limitations of the Thermal-Optical Trapezoid Model (TOTRAM), i.e., non aplicability to satellites that do not provide thermal data, and the requirement of parametrization for each individual date. Based on Short Wave Infrared Reflectance (SWIR), Normalized Difference Vegetation Index (NDVI) and in situ measurements at surface level, the OPTRAM has demostrated to be a significant advance for remote sensing of soil moisture with great importance to undestand seasonal dynamics, water resource planning and agricultural production.\n",
    "\n",
    "The present work its a implementation of the OPTRAM based on the paper [sadegui et al 2017](https://www.sciencedirect.com/science/article/abs/pii/S0034425717302493), however some differences are worth mentioning: \n",
    "\n",
    "- Only the Galnut Gulch Watershed area has been modelized, leaving aside Little Washita.\n",
    "- 71 Sentinel2 BOA (Level 2A) images corresponding to 2019 TOA (Level 1C) have been used, in contrast to the 17 images corresponding to the year 2015 used in the article. Because of BOA level, radiometric, atmospheric and geometric corrections were not needed.\n",
    "\n",
    "- The Sentinel2 [SCL](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-2-msi/level-2a/algorithm) band was used as a single mask to filter water bodies, clouds, saturated pixels, etc, as a consequence, the clustering and water body classification models of the original article were not necessary.\n",
    "\n",
    "- Both methods for the estimation of the $\\theta_d$, $\\theta_w$ coefficients, corresponding to the two scenarios presented in the original article have been implemented, although only the first scenario is fully developed.\n",
    "\n",
    "\n",
    "Adittionaly in some parts, the implementation makes advantage of parallel computations to process the tens of millions of data to be computed in a single computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d37b84",
   "metadata": {},
   "source": [
    "This notebook is divided in the following sections: \n",
    "\n",
    "\n",
    "1. [Python packages](#section_1)\n",
    "2. [Functions](#section_2)\n",
    "3. [Region of study](#section_3)\n",
    "4. [Data](#section_4)\n",
    " - [4.1 Sensor](#section_4_1)\n",
    " - [4.2 Satellite](#section_4_1)\n",
    "5. [Data fusion](#section_5)\n",
    "6. [Model parametrization](#section_6)\n",
    "7. [W maps](#section_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e5a3d3",
   "metadata": {},
   "source": [
    "To a fully understand of this work the reader should first become familiar with the original paper since the theoretical background is not discussed here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ee2884",
   "metadata": {},
   "source": [
    "<a id='section_1'></a>\n",
    "## 1 - Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad5526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODULE                                             # DESCRIPTION\n",
    "import numpy as np                                   # scientific computing\n",
    "import numpy.ma as ma                                # numpy masked arrays\n",
    "import pandas as pd                                  # data analysis and manipulation\n",
    "import geopandas as gpd                              # geospatial data analysis\n",
    "import utm                                           # bidirectional UTM-WGS84 converter\n",
    "import folium                                        # interactive data visualization\n",
    "import re                                            # regular expressions\n",
    "from osgeo import gdal, gdalconst                    # raster and geospatial data proc.\n",
    "import rasterio as rs                                # raster and geospatial data proc.\n",
    "import matplotlib.pyplot as plt                      # create visualizations\n",
    "import seaborn as sns\n",
    "import datetime                                      # datetime manipulation\n",
    "import glob                                          # unix pathname expansion\n",
    "import haversine as hs                               # distances between points\n",
    "import dask                                          # parallel computing\n",
    "from dask.distributed import Client                  # set custom parameters in cluster\n",
    "import dask.dataframe as dd                          # manipulation of lazy dask dfs\n",
    "import datashader as ds                              # visualization for big data\n",
    "import colorcet as cc                                # colormaps for datashader \n",
    "from sklearn import linear_model                     # regression \n",
    "from sklearn.metrics import mean_absolute_error      # to compute MAE\n",
    "from sklearn.metrics import mean_squared_error       # to compute RMSE\n",
    "from sklearn.metrics import r2_score                 # to compute R^2\n",
    "import xarray as xr                                  # efficent ND arrays manipulation\n",
    "import rioxarray                                     # rasterio xarray extension\n",
    "from matplotlib.colors import LinearSegmentedColormap# create custom color maps\n",
    "from shapely import geometry                         # manipulate planar features\n",
    "from shapely.geometry import Point                   # manipulate planar features\n",
    "import pickle                                        # load/save pickle datasets\n",
    "import os                                            # miscellaneous OS interfaces\n",
    "from pathlib import Path                             # \n",
    "import math                                          #\n",
    "import random                                        #  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434c9157",
   "metadata": {},
   "source": [
    "<a id='section_2'></a>\n",
    "## 2 -  Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cfd295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utm_to_latlon(coords, zone_number = 12, zone_letter = 'N'):\n",
    "    easting = coords[0]\n",
    "    northing = coords[1]\n",
    "    return utm.to_latlon(easting, northing, zone_number, zone_letter)\n",
    "\n",
    "def S2_getDate(filename) :\n",
    "    basename = Path(filename).stem  \n",
    "    try :\n",
    "        found = re.search('S2(A|B)2A_(\\d+)_.*',basename).group(2)\n",
    "        dt = datetime.datetime.strptime(found, '%Y%m%d')\n",
    "        \n",
    "    except AttributeError:\n",
    "        raise ValueError('Error: Date can not be extracted from filename %s .' % filename)\n",
    "        \n",
    "    return dt\n",
    "\n",
    "def S2_getIndex(BASE_DIR, date) :\n",
    "    \n",
    "    if (isinstance(date, datetime.date)) : \n",
    "        date_str = date.strftime(\"%Y%m%d\")\n",
    "    \n",
    "    elif (isinstance(date, str)):\n",
    "        print('\"str\" type object detected, converting to datetime.')\n",
    "        date_obj = datetime.datetime.strptime(date, \"%Y%m%d\") \n",
    "        date_str = date_obj.strftime(\"%Y%m%d\")\n",
    "        \n",
    "    else : \n",
    "        raise TypeError('Error:  %s encountered, but \"str\" o \"datetime.date\" expected' % type(date))\n",
    "    \n",
    "    pattern = BASE_DIR + '*' + date_str + '*'\n",
    "    \n",
    "    try: \n",
    "        filepath = glob.glob(pathname = pattern)\n",
    "        return filepath[0]\n",
    "    \n",
    "    except AttributeError: \n",
    "        print('Error: File with pattern %s not found' % pattern)\n",
    "        \n",
    "def S2_get_sensing_dt(boa_fp):\n",
    "    days_offset = 1\n",
    "    start_dt = S2_getDate(boa_fp) - datetime.timedelta(days=days_offset)\n",
    "    end_dt   = S2_getDate(boa_fp) + datetime.timedelta(days=days_offset)\n",
    "    \n",
    "    start_dt = start_dt.strftime('%Y-%m-%d')\n",
    "    end_dt   = end_dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    now = datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "    print('[%s] : Requesting image metadata between %s <-> %s...' % (now, start_dt, end_dt))\n",
    "    # bash callback: \n",
    "    dts = ! Rscript ./sen2r/sat_sensing_dt.R $start_dt $end_dt ./sen2r/Walnut-Gulch.geojson 2> /dev/null\n",
    "    print('[%s] : Done\\n' % datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))\n",
    "\n",
    "    sensing_datetime = datetime.datetime.strptime(dts[1], '                                        \"%Y-%m-%d %H:%M:%S UTC\" ')\n",
    "    return sensing_datetime\n",
    "\n",
    "\n",
    "def get_px_coords_from_raster(boa, no_data, band) :\n",
    "    print('[%s] : Retrieving px location coords...' % (datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")))\n",
    "    dataset = boa\n",
    "    val = boa.read(band, masked = True)\n",
    "    geometry = [Point(dataset.xy(x,y)[0],dataset.xy(x,y)[1]) for x,y in np.ndindex(val.shape) if val[x,y] != no_data]\n",
    "    coords_utm = [(point.x, point.y)  for point in geometry]\n",
    "    print('[%s] : Done\\n' % datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))\n",
    "    return (zip(*coords_utm))\n",
    "\n",
    "\n",
    "def build_inSitu_obs(df, dest_lat_lng, sensor_df, dists, sensor_name, utm_n = 12, utm_z = 'N') :\n",
    "    \n",
    "    # Calculate the closest image pixel(row) to the sensor\n",
    "    x = df.loc[:,'utm_x'].tolist()\n",
    "    y = df.loc[:,'utm_y'].tolist()\n",
    "\n",
    "    df['dist'] = dists\n",
    "    df['sensor_name'] = sensor_name\n",
    "    print('[%s] : Sorting %d rows...' % (datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"), len(df)))\n",
    "    df.sort_values('dist', inplace = True)\n",
    "    print('[%s] : Done\\n' % datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))\n",
    "\n",
    "    df = df.head(1)\n",
    "    df.set_index('datetime', inplace = True) # indexing is costly, but only one 1 obs, see previous line\n",
    "    \n",
    "    # Get the corresponding sensor obs to the pixel\n",
    "    #https://stackoverflow.com/questions/32237862/find-the-closest-date-to-a-given-date\n",
    "    def nearest(items, pivot):\n",
    "        return min(items, key=lambda x: abs(x - pivot))\n",
    "              \n",
    "    nearest_dt = nearest(items = sensor_df.index, pivot = df.index[0])\n",
    "    val = sensor_df.loc[sensor_df.index == nearest_dt, 'SM5'].values\n",
    "    print('nearest_dt: %s, %s'% (nearest_dt, val))\n",
    "    df.loc[:,'SM5'] = float(val)\n",
    "    df.loc[:,'theta_d'] = float(sensor_df.loc[:,\"SM5\"].dropna().min())\n",
    "    df.loc[:,'theta_w'] = float(sensor_df.loc[:,\"SM5\"].dropna().max())\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_haversine_dist_df(utm_coords, sensor_coords, sensor_name, utm_n = 12, utm_z = 'N') : \n",
    "    print('[%s] : Calculating haversine distance for sensor %s...'\n",
    "          % (datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"), sensor_name))\n",
    "    \n",
    "    dists = [  hs.haversine(utm_to_latlon(utm_coord, utm_n, utm_Z),\n",
    "                            sensor_coords, unit = hs.Unit.METERS)\n",
    "        \n",
    "               for utm_coord in utm_coords \n",
    "    ]\n",
    "    \n",
    "    print('[%s] : Done\\n' % datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))\n",
    "    dists = [float(dist) for dist in dists]\n",
    "    return(dists)\n",
    "\n",
    "def get_distances_pxs_to_sensor(boa_dummy, sensors_coords, utm_x, utm_y):\n",
    "    h_dists = { sensor_name : get_haversine_dist_df(utm_coords = zip(utm_x, utm_y),\n",
    "                                                    sensor_coords = sensors_coords[sensor_name],\n",
    "                                                    sensor_name = sensor_name) \n",
    "                    for sensor_name, sensor_coords in sensors_coords.items()} \n",
    "    return (h_dists)\n",
    "\n",
    "def resample_raster_gdal_nn(input_file, ref_file, out_file):\n",
    "    # Opening input\n",
    "    input = gdal.Open(input_file, gdalconst.GA_ReadOnly)\n",
    "    inputProj = input.GetProjection()\n",
    "    inputTrans = input.GetGeoTransform()\n",
    "\n",
    "    # Opening ref\n",
    "    reference = gdal.Open(ref_file, gdalconst.GA_ReadOnly)\n",
    "    referenceProj = reference.GetProjection()\n",
    "    referenceTrans = reference.GetGeoTransform()\n",
    "    bandreference = reference.GetRasterBand(1)    \n",
    "    x = reference.RasterXSize \n",
    "    y = reference.RasterYSize\n",
    "\n",
    "    # Resampling\n",
    "    driver= gdal.GetDriverByName('GTiff')\n",
    "    output = driver.Create(out_file,x,y,1,bandreference.DataType)\n",
    "    output.SetGeoTransform(referenceTrans)\n",
    "    output.SetProjection(referenceProj)\n",
    "    gdal.ReprojectImage(input,output,inputProj,referenceProj,gdalconst.GRA_NearestNeighbour)\n",
    "    del output\n",
    "    del input\n",
    "    del reference\n",
    "\n",
    "def add_scl_col(scl_fp, ndvi_fp, local_df, date,  scl_dir = \"./sen2r/out/SCL_res10/\"):\n",
    "    if os.path.isdir(scl_dir):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(scl_dir)\n",
    "    \n",
    "    if (isinstance(date, datetime.date)) : \n",
    "        date_str = date.strftime(\"%Y%m%d\")\n",
    "    \n",
    "    elif (isinstance(date, str)):\n",
    "        print('\"str\" type object detected, converting to datetime.')\n",
    "        date_obj = datetime.datetime.strptime(date, \"%Y%m%d\") \n",
    "        date_str = date_obj.strftime(\"%Y%m%d\")\n",
    "        \n",
    "    else : \n",
    "        raise TypeError('Error:  %s encountered, but \"str\" o \"datetime.date\" expected' % type(date))\n",
    "        \n",
    "    scl_10_fp = os.path.join(scl_dir, date_str + \"_SCL_10m_resampled_by_gdal.tif\")\n",
    "    resample_raster_gdal_nn(input_file = scl_fp,\n",
    "                            ref_file   = ndvi_fp,\n",
    "                            out_file   = scl_10_fp)\n",
    "\n",
    "    scl_10_dataset  = rs.open(scl_10_fp)\n",
    "    scl_10          = scl_10_dataset.read(1, masked = True)\n",
    "    scl_10_flatten  = np.ndarray.flatten(scl_10) \n",
    "\n",
    "    # TODO: May this be precomputed for speed-up ?\n",
    "    #   - Theoretically yes, since the SCL resampled rasters should have the same dims \n",
    "    x,y = get_px_coords_from_raster(scl_10_dataset,\n",
    "                                    no_data = 0,\n",
    "                                    band = 1) \n",
    "\n",
    "    scl_10_df = pd.DataFrame({\n",
    "        'utm_x' : x,\n",
    "        'utm_y' : y,\n",
    "        'scl_value' : np.delete(scl_10_flatten, scl_10_flatten == 0)\n",
    "    })\n",
    "    scl_10_df = scl_10_df.astype('int')    \n",
    "    local_df = pd.merge(local_df, scl_10_df, on = [\"utm_x\", \"utm_y\"], how = \"left\")\n",
    "    return(local_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba75ad1a",
   "metadata": {},
   "source": [
    "<a id='section_3'></a>\n",
    "## 3 -  Region of study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0702c07",
   "metadata": {},
   "source": [
    "The South Watershed Reseach Center (SWRC) operates the Walnut Gulch (WG) Experimental Watershed in southeastern Arizona as an outdoor laboratory for studying semiarid rangeland hydrologic, ecosystem, climate, and erosion processes.\n",
    "\n",
    "The SWRC hidrology network is densely instrumented with sensors associated with weather stations, soil profile trenches and 52 near-surface soil hydrology sensors co-located with rain gauges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eb35b2",
   "metadata": {},
   "source": [
    "The WG wathersed is part of the San Pedro river basein and extends over an area of 148Km² covered with shrubs (two thirds) adnd grassland (one third). \n",
    "The climate is semiarid with an average annual temperature of 17.7 ºC and average annual precipitation of 350 mm, commonly falling between April and September. \n",
    "Soils are classified as gravely and sandly loams with a high percentage of rock and gravel close to the soil surface. - Sadegui et al 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a57a2b",
   "metadata": {},
   "source": [
    "For more information about the area, check this links: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c1e78f",
   "metadata": {},
   "source": [
    "- https://www.tucson.ars.ag.gov/dap/\n",
    "- https://www.tucson.ars.ag.gov/dap/dap_docs/soil.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca18a5",
   "metadata": {},
   "source": [
    "For the year 2019, 19 sensors with 5 cm Volumetric Water Content (%) are available. The process of the sensor data retrieving is detailed in this issue:\n",
    "- https://github.com/VicenteYago/OPTRAM/issues/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faaf1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "swrc_wg = gpd.read_file('./WG-boundary/boundary/boundary.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb065be6",
   "metadata": {},
   "source": [
    "Plotting with Folium requires lat, long data, so we have to convert from UTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0473920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arizona\n",
    "utm_N = 12 \n",
    "utm_Z = 'N'\n",
    "\n",
    "x,y = swrc_wg.geometry[0].exterior.coords.xy\n",
    "points = []\n",
    "for i in range(len(swrc_wg.geometry[0].exterior.coords.xy[1])) : \n",
    "    points.append(utm_to_latlon(coords = [x[i], y[i]],\n",
    "                                zone_number = utm_N,\n",
    "                                zone_letter = utm_Z))\n",
    " \n",
    "\n",
    "points_rev = [(y,x) for x,y in points]\n",
    "swrc_wg['geometry'] = geometry.Polygon(points_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364ce154",
   "metadata": {},
   "source": [
    "Also we want to plot the locations of ground probes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909efc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tucson.ars.ag.gov/dap/dap_docs/soil.html\n",
    "\n",
    "\n",
    "sensor_coords_utm = {'rg13vt19'  : [586110, 3510185],\n",
    "                     'rg14vt19'  : [585442, 3507187],\n",
    "                     #'rg18vt19'  : [586710, 3508098],\n",
    "                     'rg20vt19'  : [587480, 3504939],\n",
    "                     'rg28vt19'  : [590624, 3509990],\n",
    "                     'rg34vt19'  : [590946, 3507458],\n",
    "                     'rg37vt19'  : [593303, 3506068],\n",
    "                     'rg40vt19'  : [593360, 3510286],\n",
    "                     'rg46vt19'  : [595289, 3508655],\n",
    "                     'rg57vt19'  : [596089, 3510781],\n",
    "                     'rg69vt19'  : [603916, 3515463],\n",
    "                     'rg70vt19'  : [604288, 3514207],\n",
    "                     'rg76vt19'  : [582624, 3509679],\n",
    "                     'rg82vt19'  : [600154, 3511680],\n",
    "                     'rg83vt19'  : [589679, 3512426],\n",
    "                     'rg89vt19'  : [596308, 3513931],\n",
    "                     'rg92vt19'  : [581888, 3511774],\n",
    "                     'rg100vt19' : [593266, 3504720]\n",
    "}\n",
    "\n",
    "sensors_coords = {s_key : utm_to_latlon(s_utm, utm_N, utm_Z) \n",
    "                  for s_key, s_utm in sensor_coords_utm.items()}\n",
    "\n",
    "m = folium.Map(location = [31.713068,  -110.025442],\n",
    "               zoom_start = 11,\n",
    "               tiles = \"CartoDB positron\")\n",
    "\n",
    "for _, r in swrc_wg.iterrows():\n",
    "    sim_geo = gpd.GeoSeries(r['geometry']).simplify(tolerance=0.001)\n",
    "    geo_j = sim_geo.to_json()\n",
    "    geo_j = folium.GeoJson(data=geo_j,\n",
    "                           style_function=lambda x: {'fillColor': 'orange'})\n",
    "    geo_j.add_to(m)\n",
    "    \n",
    "for sensor_key, sensor_coords in sensors_coords.items():\n",
    "    \n",
    "    folium.Marker(sensor_coords, popup=sensor_key).add_to(m)\n",
    "    m.add_child(folium.ClickForMarker(popup=\"Waypoint\"))\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a41a3e3",
   "metadata": {},
   "source": [
    "The soils sites are evenly distruted along the WG extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0643f034",
   "metadata": {},
   "source": [
    " Shapefile to geojson conversion, the .geojson its needed to download the Sentinel 2 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a49541",
   "metadata": {},
   "outputs": [],
   "source": [
    "swrc_wg.to_crs(epsg=4326)\n",
    "swrc_wg.to_file('./sen2r/Walnut-Gulch.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e128fac",
   "metadata": {},
   "source": [
    "<a id='section_4'></a>\n",
    "\n",
    "## 4 - DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f65fb6",
   "metadata": {},
   "source": [
    "The OPTRAM models needs intensive data from surface soil moisture sensors and satellite images. In the following subsections both sources will be detailed. This graphs summarizes the process of data processing: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a5bb72",
   "metadata": {},
   "source": [
    "<img src=\"./img/scheme_full.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88df45a7",
   "metadata": {},
   "source": [
    "- **1-3** : Sensor processing, the filtering of incomplete sensors will be performed here.\n",
    "- **4-8** : Very complex but made easy by [sen2r](http://sen2r.ranghetti.info/index.html) library in R, rasterio and gdal in python.\n",
    "- **9**   : This data fusion is key to obtain a full implementation of the OPTRAM model. The sensor readings of each station are matched with the nearest pixels of each image at the acqusition time, allowing for volumetric content water (%) predictions once the model is validated. Aditionally a big speed up is achieved using the parallel library [Dask](https://dask.org/). \n",
    "- **10**  : The Scheme Classification Layer ([SCL](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-2-msi/level-2a/algorithm)) already computed by Copernicus is used to mask the defective pixels, i.e., clouds, snow, shadows, etc.\n",
    "- **11**  : Finally, with the filtered data and inSitu fusion observations the OPTRAM can be fitted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14deb707",
   "metadata": {},
   "source": [
    "<a id='section_4_1'></a>\n",
    "### 4.1  Sensor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab564f04",
   "metadata": {},
   "source": [
    "The OPTRAM model is intended for near surface soil water content estimation, so the SM5 (5 cm depth) its the only level we parse. The following document presents a comprehensive description of the data retrieved from the sensors: \n",
    "- https://www.tucson.ars.ag.gov/metDAP/MetandSoil_ColumnHeaders.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f42ce",
   "metadata": {},
   "outputs": [],
   "source": [
    " %%time\n",
    "\n",
    "sensor_path = \"./sensor_data\"\n",
    "sensors_df = {}\n",
    "    \n",
    "if False: \n",
    "    # TODO : check existence of sensor_path folder\n",
    "    names = [\"site\", \"year\", \"day\", \"hr\", \"mn\", \"SM5\", \"SM15\", \"SM30\", \"SM50\", \"SM75\", \"SM100\", \"SM200\"]\n",
    "    url_base = 'https://www.tucson.ars.ag.gov/metDAP/'\n",
    "    for sensor_key,_ in list(sensors_coords.items()) :\n",
    "        print(\"Processing sensor %s\" % sensor_key)\n",
    "        try: \n",
    "            if 'rg' in sensor_key :\n",
    "\n",
    "                sensors_df[sensor_key] = pd.read_csv(url_base + 'RaingageSiteData/' + sensor_key +'.out',\n",
    "                                                     sep='\\,', \n",
    "                                                     names = names,\n",
    "                                                     engine='python')\n",
    "            else :\n",
    "                sensors_df[sensor_key] = pd.read_csv(url_base + 'SoilProfileSiteData/' + sensor_key +'.out',\n",
    "                                                     sep='\\s+', \n",
    "                                                     names = names,\n",
    "                                                     engine='python')\n",
    "\n",
    "\n",
    "            sensors_df[sensor_key]['datetime'] = (pd.to_datetime(sensors_df[sensor_key]['year'] * 1000 + sensors_df[sensor_key]['day'], format='%Y%j') \n",
    "                                                  +\n",
    "                                                  pd.to_timedelta(sensors_df[sensor_key][\"hr\"], unit=\"h\") \n",
    "                                                  +\n",
    "                                                  pd.to_timedelta(sensors_df[sensor_key][\"mn\"], unit=\"min\"))\n",
    "\n",
    "            sensors_df[sensor_key].set_index('datetime', inplace=True)\n",
    "            sensors_df[sensor_key].replace(6999, None, inplace=True) \n",
    "            sensors_df[sensor_key].to_parquet(os.path.join(sensor_path, sensor_key+\".parquet\"), engine=\"fastparquet\")\n",
    "\n",
    "            #print(sensors_df[sensor_key].index)\n",
    "\n",
    "\n",
    "        except Exception as e :\n",
    "            print(\"An error occurred while reading data for sensor %s \" % sensor_key)\n",
    "            print(\"Original message: %s \" % e)\n",
    "            sensors_df.pop(sensor_key, None)\n",
    "            sensors_coords.pop(sensor_key, None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5312655d",
   "metadata": {},
   "source": [
    "Both rg82 & rg83 need custom processing because the datetimes are formatted in a different way, but in this occasion I am going to excluded it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c47f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_coords.pop('rg82vt19',None)\n",
    "sensors_coords.pop('rg83vt19',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ad3112",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for sensor_parquet in os.listdir(sensor_path): \n",
    "    sensors_df[os.path.splitext(sensor_parquet)[0]] = pd.read_parquet(os.path.join(sensor_path, sensor_parquet), engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6932e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_nums = 1  \n",
    "row_nums = math.ceil(len(sensors_df.items()) / col_nums)\n",
    "plt.figure(figsize=(20, 35))\n",
    "for i, (k, df) in enumerate(sensors_df.items(), 1):\n",
    "    df = sensors_df[k]\n",
    "    plt.subplot(row_nums, col_nums, i)\n",
    "    plt.scatter(x = df.index, y= df.loc[:,'SM5'])\n",
    "    plt.title(k)\n",
    "    plt.xlim([datetime.date(2019, 1, 1), datetime.date(2020, 1, 1)])\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=2 , wspace=None, hspace=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7244826",
   "metadata": {},
   "source": [
    "We can see some sensors have wide ranges of lost observations: \n",
    "- **rg37vt19**\n",
    "- **rg100vt19**\n",
    "- **rg40vt19**\n",
    "\n",
    "These lost observartions are a serious problem since the OPTRAM needs the max and min values of each series to obtain a meaningful overall fit. Thus we proceed to remove the faulty sensors: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b112b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_sensors = ['rg37vt19', 'rg100vt19', 'rg40vt19']\n",
    "\n",
    "for k in bad_sensors : \n",
    "    sensors_coords.pop(k, None)\n",
    "    sensors_df.pop(k, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32fa990",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sensors_coords.keys()))\n",
    "print(len(sensors_df.keys()))\n",
    "\n",
    "print(sensors_coords.keys())\n",
    "print(sensors_df.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a43b41c",
   "metadata": {},
   "source": [
    "<a id='section_4_2'></a>\n",
    "### 4.2 - Satellite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb69584",
   "metadata": {},
   "source": [
    "The sattelity imagery has been downloaded with the library [sen2r](http://sen2r.ranghetti.info/index.html). This library is very useful to not only download seamlessly but for processing and computation of a varios range of products such as NDVI, here is a list of the tasks performed by the library: \n",
    "\n",
    "- Query S2 images in a date range [2019-01-01 to 2020-01-01]\n",
    "- Download the SAFE products (BOA reflectance) from [gcloud](https://luigi.ranghetti.info/post/safe-gcloud/) and scihub.\n",
    "- Download SCL band\n",
    "- Warp tiles to WG shape\n",
    "- Resample SWIR band from 20mts to 10mts/px to match the R and NIR bands\n",
    "- Compute NDVI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d8a053",
   "metadata": {},
   "source": [
    "The library runs in R, so the code its scripted in the file `./sen2r/s2.R`. The outputs are stored in a set of folders specified in the config file : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719d969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat ./sen2r/inputs-config_scihub.json | head -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1a244e",
   "metadata": {},
   "source": [
    "Once the images are procesed, the files are located in the following dirs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4346209",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = './'\n",
    "BASE_DIR_BOA = os.path.join(BASE_DIR, 'sen2r/out/BOA2/')\n",
    "BASE_DIR_SCL = os.path.join(BASE_DIR, 'sen2r/out/SCL/')\n",
    "BASE_DIR_NDVI = os.path.join(BASE_DIR, 'sen2r/indices/NDVI/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa7879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR_SAT_IMG_DF = os.path.join(BASE_DIR, 'sat_img_df/')\n",
    "boa_files = [f for f in os.listdir(BASE_DIR_BOA,) if os.path.isfile(os.path.join(BASE_DIR_BOA, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c5dc5",
   "metadata": {},
   "source": [
    "UTM coordinates of each pixel will be needed in order to find the nearest pixel to the weather stations, so instead of calculate it in each iteration of the following loop, they are pre-computed taking advantage of the fact that all images have the exact same dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef04aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----PRECALCULATED for speedup\n",
    "# TODO: Parellization will be great, but its not worth bc it will be computed one time \n",
    "# and them the result will be loaded for further runnings.\n",
    "if False :\n",
    "    print('[%s] : ------- PRECOMPUTING  -------\\n' % (datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")))\n",
    "    boa_dummy  = rs.open(BASE_DIR_BOA + boa_files[0])\n",
    "    utm_x, utm_y =  get_px_coords_from_raster(boa_dummy,\n",
    "                                              band = 3, # /10 m/px band\n",
    "                                              no_data = boa_dummy.nodata)\n",
    "    print('[%s] : ----- PRECOMPUTING DONE -----\\n' % (datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4160da75",
   "metadata": {},
   "source": [
    "A dataframe representation of each image is built, computing NDVI, STR and SCL resampled values as columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d2a019",
   "metadata": {},
   "source": [
    "$$NDVI = \\frac{R_{NIR} - R_{RED}}{R_{NIR} + R_{RED}}$$\n",
    "$$STR = \\frac{(1-R_{SWIR})^2}{2 \\cdot R_{SWIR}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e2906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False : \n",
    "    \n",
    "    Path(BASE_DIR_SAT_IMG_DF).mkdir(parents=True, exist_ok=True)\n",
    "    for idx,file in enumerate(boa_files) : \n",
    "        try : \n",
    "            now = datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "            print('[%s] : processing file (%s/%s) %s... \\n' % (now, idx, len(boa_files), file))\n",
    "\n",
    "            boa_fp = BASE_DIR_BOA + file\n",
    "            raster_date = S2_getDate(boa_fp)\n",
    "            scl_fp = S2_getIndex(BASE_DIR_SCL, raster_date)\n",
    "            ndvi_fp = S2_getIndex(BASE_DIR_NDVI, raster_date)\n",
    "\n",
    "            boa  = rs.open(boa_fp)\n",
    "            ndvi  = rs.open(ndvi_fp)\n",
    "\n",
    "            swir = boa.read(11, masked = True)\n",
    "            ndvi = ndvi.read(1)\n",
    "            ndvi = np.ndarray.flatten(ndvi)\n",
    "            ndvi = np.delete(ndvi, ndvi == -9999.0)\n",
    "            #SWIR2 band 12 http://sen2r.ranghetti.info/articles/outstructure.html\n",
    "            swir = swir / 10000 \n",
    "            STR  = ((1-swir)**2)/(2*swir)\n",
    "            STR  = np.ndarray.flatten(STR)\n",
    "            STR  = np.delete(STR, STR.mask)\n",
    "            \n",
    "            data = {\n",
    "                'datetime' : S2_get_sensing_dt(boa_fp),\n",
    "                'ndvi' : ndvi,\n",
    "                'str'  : STR,\n",
    "                'utm_x' : utm_x, \n",
    "                'utm_y' : utm_y,\n",
    "                'fpath' : boa_fp\n",
    "            }\n",
    "            \n",
    "            local_df = pd.DataFrame(data)\n",
    "            local_df.astype({\n",
    "                'datetime' : 'datetime64[ns]',\n",
    "                'ndvi' : 'float', \n",
    "                'utm_x' : 'float', \n",
    "                'utm_y' : 'float',\n",
    "                'fpath' : 'str'\n",
    "            })\n",
    "            local_df = add_scl_col(scl_fp = scl_fp,\n",
    "                                   ndvi_fp = ndvi_fp,\n",
    "                                   local_df = local_df,\n",
    "                                   date = raster_date)            \n",
    "            local_df.to_parquet(os.path.join(BASE_DIR_SAT_IMG_DF,\n",
    "                                             datetime.datetime.strftime(raster_date, \"%Y-%m-%d\")+\".parquet\"),\n",
    "                                engine=\"fastparquet\")\n",
    "                \n",
    "            #print(local_df)\n",
    "            \n",
    "        except Exception as e : \n",
    "            print(\"An error occurred while processing data for file %s \" % file)\n",
    "            print(\"Original message: %s \" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1759e128",
   "metadata": {},
   "source": [
    "Here is a look at the data of an example image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1094624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(os.path.join(BASE_DIR_SAT_IMG_DF, os.listdir(BASE_DIR_SAT_IMG_DF)[0]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ce368e",
   "metadata": {},
   "source": [
    "Quick remarks: \n",
    "- The `datetime` is the sensing datetime of the image, retrieved with a `sen2r` script.\n",
    "- Why are `NaN` values in the`scl` column?\n",
    "  - In sort, its due to a left join, affecting only at some  pixels in the image margins. See this [issue](https://github.com/VicenteYago/OPTRAM/issues/4 ) for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19d5e87",
   "metadata": {},
   "source": [
    "It can be check that `NaN` SCL values are a small fraction of the total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143b0a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df['scl_value'], return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e74c9b4",
   "metadata": {},
   "source": [
    "<a id='section_5'></a>\n",
    "## 5 - Data fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa7b0bd",
   "metadata": {},
   "source": [
    "To match the satellite values with the sensor readings, first the closest pixel to each station needs to be find."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb5faf",
   "metadata": {},
   "source": [
    "The following code precalculates the distance (haversine) to the >1M points of the satellite image to each of the sensing stations (~13). The precalculation is done with a dummy image (first boa file) because all the ~74 images have the same dimensions and georeference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c492aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print('[%s] : ------- PRECOMPUTING  -------\\n' % (datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")))\n",
    "    haversine_dists = get_distances_pxs_to_sensor(boa_dummy = boa_dummy,\n",
    "                                                  sensors_coords = sensors_coords,\n",
    "                                                  utm_x = utm_x,\n",
    "                                                  utm_y = utm_y)\n",
    "    print('[%s] : ----- PRECOMPUTING DONE -----\\n' % (datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")))\n",
    "    with open('./haversine_dists.pkl', 'wb') as f:\n",
    "        pickle.dump(haversine_dists, f)\n",
    "        \n",
    "with open('./haversine_dists.pkl', 'rb') as f:\n",
    "    haversine_dists = pickle.load(f) #TODO: Will be great to save as parquet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc6d3e6",
   "metadata": {},
   "source": [
    "From here to the end we will use **Dask** to speedup the computations unlocking the parallelism at hardware level, to learn more about it : \n",
    "\n",
    "- https://dask.org/\n",
    "- https://docs.dask.org/en/latest/dataframe.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aad5b0",
   "metadata": {},
   "source": [
    "\n",
    "First of all the client need to be set, I have followed the recommendations :\n",
    "[_You want the number of processes times the number of threads to equal the number of cores._](https://stackoverflow.com/questions/51099685/best-practices-in-setting-number-of-dask-workers)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d103ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ryzen 5 2600: 6 cores 12 threads, 16 GB RAM\n",
    "# Workaround to achieve scheduler similar to processes=False\n",
    "client = Client(memory_limit='16GB', # keep to 12\n",
    "                processes = True,\n",
    "                n_workers = 1,\n",
    "                threads_per_worker = 12)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eacab56",
   "metadata": {},
   "source": [
    "Loading lazily all the dataframes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9183ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.read_parquet(BASE_DIR_SAT_IMG_DF + \"*\", engine='fastparquet')\n",
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d615172",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False :\n",
    "    ddf.info(memory_usage=True) # 6GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76061b80",
   "metadata": {},
   "source": [
    "The following cell apply the `build_inSitu_obs()` function to each of the images (partitions of delayed dataframe `ddf`) in parallel.\n",
    "\n",
    "Basically the matching between the sensors observations (SM5) and the satellite imagery occurs here. Additionally $\\theta_w$ $\\theta_d$ for each sensor (station) is added to the result to make the predictions in the OPTRAM fit stage.\n",
    "\n",
    "In each iteration a dataframe called `inSitu_obs_df` is generated with all the insitu measurements of the current sensor at the sensing datetime for all the images. Finally all the dataframes are concatenated into one conforming the `inSitu_dfs_global` df.\n",
    "\n",
    "The funny thing is no computation is done actually here, instead a parallelized task graph is created by dask to be computed along the workers defined previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0909478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True : \n",
    "    \n",
    "    #https://docs.dask.org/en/stable/generated/dask.dataframe.DataFrame.map_partitions.html\n",
    "    #An empty pd.DataFrame or pd.Series that matches the dtypes and column names\n",
    "    #of the output. \n",
    "    meta = pd.DataFrame({\n",
    "                  'datetime':    pd.Series(dtype='datetime64[ns]'),\n",
    "                  'ndvi':        pd.Series(dtype='float'),\n",
    "                  'str':         pd.Series(dtype='float'),\n",
    "                  'utm_x':       pd.Series(dtype='float'),\n",
    "                  'utm_y':       pd.Series(dtype='float'),\n",
    "                  'fpath':       pd.Series(dtype='str'),\n",
    "                  'scl_value':   pd.Series(dtype='int'),\n",
    "                  # added by `build_inSitu_obs`  \n",
    "                  'dist':        pd.Series(dtype='float'),\n",
    "                  'sensor_name': pd.Series(dtype='str'),\n",
    "                  'SM5':         pd.Series(dtype='float'),\n",
    "                  'theta_d':     pd.Series(dtype='float'),\n",
    "                  'theta_w':     pd.Series(dtype='float')\n",
    "    })\n",
    "    \n",
    "    meta.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "    inSitu_obs_dfs_list = list()\n",
    "    for sensor_name, sensor_coords in sensors_coords.items() :\n",
    "        now = datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "        print('[%s] : processing sensor %s... \\n' % (now, sensor_name))\n",
    "        try : \n",
    "\n",
    "            inSitu_obs_df = ddf.map_partitions(build_inSitu_obs, \n",
    "                                               dest_lat_lng  = sensors_coords[sensor_name],\n",
    "                                               sensor_df     = sensors_df[sensor_name],\n",
    "                                               dists         = haversine_dists[sensor_name],\n",
    "                                               sensor_name   = sensor_name,\n",
    "                                               meta = meta);\n",
    "\n",
    "            inSitu_obs_dfs_list.append(inSitu_obs_df)\n",
    "            del inSitu_obs_df\n",
    "        except Exception as e : \n",
    "            print(\"An error occurred while processing data for sensor %s \" % sensor_name)\n",
    "            print(\"Original message: %s \" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b96bf7c",
   "metadata": {},
   "source": [
    "The following cell fully exploits CPU parallelism but requires lots of memory to fit and inizialize the tasks. See [best practices, section __Avoid calling compute repeatedly__](https://docs.dask.org/en/latest/best-practices.html) \n",
    "\n",
    "We can see the task graph: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a77510",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.visualize(*inSitu_obs_dfs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed92c77",
   "metadata": {},
   "source": [
    "But its so massive it can not fit properly in jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6097c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recomended 64 GB memory\n",
    "# the task graph initialization takes up 18 GB alone\n",
    "if False : #do not run\n",
    "    inSitu_dfs_global = dask.compute(*inSitu_obs_dfs_list)\n",
    "    inSitu_dfs_global = pd.concat(inSitu_dfs_global)\n",
    "    \n",
    "    with open('./inSitu_dfs_global.pkl', 'wb') as f:\n",
    "        pickle.dump(inSitu_dfs_global, f)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21895a7",
   "metadata": {},
   "source": [
    "Also we can compute indepently each item, thus requiring much less memory but loading in each iteration the whole image datasets, as a consequence its takes sensibly longer (~ 15 mins) than previous.\n",
    "\n",
    "We can see the task graph for the first item: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a7879",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.visualize(inSitu_obs_dfs_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f125cab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Recomended 16 GB memory\n",
    "\n",
    "if False : #do not run\n",
    "    inSitu_dfs_global = [df.compute() for df in inSitu_obs_dfs_list]\n",
    "    inSitu_dfs_global = pd.concat(inSitu_dfs_global)\n",
    "    \n",
    "    with open('./inSitu_dfs_global.pkl', 'wb') as f:\n",
    "        pickle.dump(inSitu_dfs_global, f)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d0d5f1",
   "metadata": {},
   "source": [
    "Which alternative to use, depends on the hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f7961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./inSitu_dfs_global.pkl', 'rb') as f:\n",
    "    inSitu_dfs_global = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b5a5a9",
   "metadata": {},
   "source": [
    "Appliying the mask to mantain only pixels labeled as \"VEGETATION\" or \"NOT_VEGETATED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fd34c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (inSitu_dfs_global.loc[:,\"scl_value\"] == 4) | (inSitu_dfs_global.loc[:,\"scl_value\"] == 5) #vegetated % not_vegetated only\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea5b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inSitu_dfs_global_masked = inSitu_dfs_global.loc[mask,:]\n",
    "inSitu_dfs_global_masked.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f76d4e5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> SM5 its equivallent to $\\theta$ in the terminology of sadegui et al 2017\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3b4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The inSitu_dfs_global has %d in situ measurements, which %d are filtered due to defective values\" % (len(inSitu_dfs_global),\n",
    "                                                                                            len(inSitu_dfs_global) - len(inSitu_dfs_global_masked))  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e15fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_delayed = (ddf[\"scl_value\"] == 4) | (ddf[\"scl_value\"] == 5) #vegetated % not_vegetated \n",
    "mask = mask_delayed.compute()\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94fc4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global = ddf.loc[:,[\"str\", \"ndvi\", \"scl_value\"]].compute()\n",
    "df_global_masked = df_global.loc[mask,[\"ndvi\", \"str\"]]\n",
    "\n",
    "print(\"The df_global has %d rows (pixels), which %d are filtered due to defective values\" % (len(df_global),\n",
    "                                                                                    len(df_global) - len(df_global_masked)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf88c19f",
   "metadata": {},
   "source": [
    "Plotting such a vast amount of data requires a more specialized library. [Datashader](https://datashader.org/index.html) is a graphics pipeline system for the representation of large datasets and in this context works very well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58280bef",
   "metadata": {},
   "source": [
    "Plotting with `datashader` requires the extent of the axes, it can be computed in parallel too:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4661dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.visualize(ddf['ndvi'].min(),\n",
    "               ddf['ndvi'].max(),\n",
    "               ddf['str'].max(),\n",
    "               ddf['str'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d894537",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_min, ndvi_max, str_min, str_max = dask.compute(ddf['ndvi'].min(),\n",
    "                                                    ddf['ndvi'].max(),\n",
    "                                                    ddf['str'].min(),\n",
    "                                                    ddf['str'].max())\n",
    "\n",
    "ndvi_min_masked, ndvi_max_masked, str_min_masked, str_max_masked = dask.compute(ddf.loc[mask_delayed,'ndvi'].min(),\n",
    "                                                                                ddf.loc[mask_delayed, 'ndvi'].max(),\n",
    "                                                                                ddf.loc[mask_delayed,'str'].min(),\n",
    "                                                                                ddf.loc[mask_delayed,'str'].max())\n",
    "\n",
    "\n",
    "\n",
    "cvs = ds.Canvas(plot_width=800, plot_height=500)\n",
    "fig, ax = plt.subplots(2,1, sharey=False, sharex=True, figsize=(15,10))\n",
    "\n",
    "# RAW PLOT\n",
    "agg_glob = cvs.points(df_global, 'ndvi', 'str')  # this is the histogram\n",
    "img_glob = ds.tf.set_background(ds.tf.shade(agg_glob, cmap=cc.fire), \"white\").to_pil()  # create a rasterized image\n",
    "ax[0].imshow(img_glob, extent=[ndvi_min, ndvi_max, str_min , str_max],\n",
    "           aspect='auto',\n",
    "           origin='upper')\n",
    "ax[0].scatter(x = inSitu_dfs_global.loc[:,\"ndvi\"],\n",
    "              y = inSitu_dfs_global.loc[:,\"str\"], label = \"inSitu_obs\")\n",
    "\n",
    "# MASKED PLOT\n",
    "agg_masked = cvs.points(df_global_masked, 'ndvi', 'str')  # this is the histogram\n",
    "img_masked = ds.tf.set_background(ds.tf.shade(agg_masked, cmap=cc.fire), \"white\").to_pil()  # create a rasterized image\n",
    "ax[1].imshow(img_masked, extent=[ndvi_min_masked,\n",
    "                                 ndvi_max_masked,\n",
    "                                 str_min_masked,\n",
    "                                 str_max_masked],\n",
    "             aspect='auto',\n",
    "             origin='upper')\n",
    "ax[1].scatter(x = inSitu_dfs_global_masked.loc[:,\"ndvi\"],\n",
    "              y = inSitu_dfs_global_masked.loc[:,\"str\"], label = \"inSitu_obs\")\n",
    "\n",
    "\n",
    "ax[0].title.set_text(\" Walnut Gulch 104M points\")\n",
    "ax[1].title.set_text(\" Walnut Gulch 77M points (SCL masked)\")\n",
    "plt.xlabel(\"NDVI\")\n",
    "plt.ylabel(\"STR\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60132e71",
   "metadata": {},
   "source": [
    "And here is the desired _NDVI-STR_ space. \n",
    "\n",
    "Quick remarks : \n",
    "\n",
    "- Its interesting to note the in situ measurements observations are clustered in the center of the trapezoid  \n",
    "\n",
    "\n",
    "\n",
    "- The higher range of NDVI values is orphaned of measurements, this will introduce additional uncertainty when actually satured pixels are confronted with the OPTRAM for predictions.\n",
    "\n",
    "\n",
    "\n",
    "- The extent of overrepresentation of measurements in the NDVI-STR space in the original paper is unknown, as no evidence of the point spread is provided, however the authors states the following : \n",
    "  - _[...]Though only a limited number o fimage were available it should be noted that measured soil moisture values varied over the full rnge from ry to satured, allowing for extensive validation fo OPTRAM and TOTRAM_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5563e3a5",
   "metadata": {},
   "source": [
    "<a id='section_6'></a>\n",
    "\n",
    "## 6 - Model parametrization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60fc442",
   "metadata": {},
   "source": [
    "Once the _NDVI-STR_ space its build the wet ($STR_w$) and dry ($STR_d$) edges need to be determined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e638f",
   "metadata": {},
   "source": [
    "The edges are modelized by simple linear regresion which coefficentes are determined by visual spection, following the recomendations of sadegui et al 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f249ac",
   "metadata": {},
   "source": [
    "$$STR_w = m_w\\cdot(NDVI - x_w) + y_w$$\n",
    "$$STR_d = m_d\\cdot(NDVI - x_d) + y_d$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7589d8",
   "metadata": {},
   "source": [
    "Then the normalized soil water content ($W$) is defined :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea03fd2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$W = \\frac{\\theta - \\theta_d}{\\theta_w - \\theta_d} =  \\frac{STR - STR_d}{STR_w - STR_d}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f8353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def W(STRd, STRw, STR):\n",
    "    return((STR - STRd)/(STRw - STRd))\n",
    "\n",
    "def STR_f(slope, ndvi, intercept):\n",
    "    intercept_x  = intercept[0]\n",
    "    intercept_y  = intercept[1]\n",
    "    return (slope*(ndvi - intercept_x) + intercept_y) # y = m(x-x1) + y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972e9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_dry_intercept = (0, -0.5)\n",
    "edge_dry_slope = 3\n",
    "\n",
    "\n",
    "edge_wet_intercept = (0, 4)\n",
    "edge_wet_slope = 11\n",
    "\n",
    "\n",
    "cvs = ds.Canvas(plot_width=800, plot_height=500)  \n",
    "plt.figure(figsize=(14, 9))\n",
    "\n",
    "agg_masked = cvs.points(df_global_masked, 'ndvi', 'str') \n",
    "img_masked = ds.tf.set_background(ds.tf.shade(agg_masked, cmap=cc.fire), \"white\").to_pil() \n",
    "plt.imshow(img_masked, extent=[ndvi_min_masked,\n",
    "                               ndvi_max_masked,\n",
    "                               str_min_masked,\n",
    "                               str_max_masked],\n",
    "           aspect='auto',\n",
    "           origin='upper')\n",
    "\n",
    "plt.scatter(x = inSitu_dfs_global_masked.loc[:, \"ndvi\"],\n",
    "            y = inSitu_dfs_global_masked.loc[:, \"str\"], label = \"inSitu_obs\")\n",
    "\n",
    "plt.axline(edge_dry_intercept, slope=edge_dry_slope,\n",
    "           linewidth = 5, color='red', label='dry_edge')\n",
    "plt.axline(edge_wet_intercept, slope=edge_wet_slope,\n",
    "           linewidth = 5, color='blue', label='wet_edge')\n",
    "\n",
    "plt.title(\" Walnut Gulch 2019 77M points\")\n",
    "plt.xlabel(\"NDVI\")\n",
    "plt.ylabel(\"STR\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f8973f",
   "metadata": {},
   "source": [
    "The `inSitu_obs` are the satellite image pixels corresponding to the locations of all the soil probes in all the images, thus becoming the ground truth or inSitu measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585a5bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inSitu_dfs_global_masked.loc[:,'str_d'] =  STR_f(intercept = edge_dry_intercept,\n",
    "                                                 slope = edge_dry_slope,\n",
    "                                                 ndvi = inSitu_dfs_global_masked.loc[:,'ndvi'])\n",
    "\n",
    "inSitu_dfs_global_masked.loc[:,'str_w'] =  STR_f(intercept = edge_wet_intercept,\n",
    "                                                 slope = edge_wet_slope,\n",
    "                                                 ndvi = inSitu_dfs_global_masked.loc[:,'ndvi'])\n",
    "\n",
    "inSitu_dfs_global_masked.loc[:,\"W\"] = W(STRd = inSitu_dfs_global_masked['str_d'],\n",
    "                                        STRw = inSitu_dfs_global_masked['str_w'],\n",
    "                                        STR  = inSitaxisu_dfs_global_masked['str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cc0089",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize = (16, 7))\n",
    "axs[0].plot('ndvi', 'str_d', 'ro', data = inSitu_dfs_global_masked)\n",
    "axs[0].plot('ndvi', 'str_w', 'bo', data = inSitu_dfs_global_masked)\n",
    "axs[0].plot('ndvi', 'str', 'kx', data = inSitu_dfs_global_masked)\n",
    "axs[0].set(xlabel=\"NDVI\", ylabel=\"STR\")\n",
    "\n",
    "#sns.regplot(x=\"ndvi\", y=\"str\", data=inSitu_dfs_global_masked, ax=axs[1])\n",
    "sns.regplot(x=\"W\", y=\"SM5\", data=inSitu_dfs_global_masked, ax=axs[1])\n",
    "#sns.regplot(x=\"str\", y=\"SM5\", data=inSitu_dfs_global_masked, ax=axs[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47c3734",
   "metadata": {},
   "source": [
    "Comments on the right graph:\n",
    "- as previously noted in the STR-NDVI space image the in situ measurements are constrained to the semi-arid space, in this image: W < 0.5\n",
    "- altough the points are concentrated in the arid range, the data exhibit a large scatter on the y-axis (SM5 aka $\\theta$), which probably is due to the inherent soil physical variability of the locations of the in Situ measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158a1365",
   "metadata": {},
   "source": [
    "### Alternative $\\theta_d$ , $\\theta_w$ estimation : Regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d5c808",
   "metadata": {},
   "source": [
    "In sadegui et al 2017, the authors propose two ways of computing the local minimun ($\\theta_d$) and maximun($\\theta_w$) values of soil moisture content based in two scenarios:\n",
    "\n",
    "- **Scenario 1** : $\\theta_d$ , $\\theta_w$ are determined via linear regression analysis of RS-based $W$ data and in situ measued $\\theta$ data.\n",
    "- **Scenario 2** : $\\theta_d$ , $\\theta_w$ are computed as the minimum and maximum $\\theta$ at each station during the sampling period.\n",
    "\n",
    "\n",
    "\n",
    "The scenario 2 $\\theta$-values are already estimated in the function `build_inSitu_obs()` and available in the column `theta_d` and `theta_w` respectively, in the `inSitu_dfs_global_masked` dataframe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b39b168",
   "metadata": {},
   "source": [
    "The scenario 1 estimation is more complex because of the need to fit a linear regresion for each station to obtain the $\\theta_d (W=0)$ and $\\theta_w (W=1)$ . The following cell computes $\\theta_d$ , $\\theta_w$ for each station and store it as `theta_d_reg` and `theta_w_reg` respectively, in the `inSitu_dfs_global_masked` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5d12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_names = np.unique(inSitu_dfs_global_masked[\"sensor_name\"])\n",
    "\n",
    "nrow = 4\n",
    "ncol = 3\n",
    "fig, axs = plt.subplots(nrow, ncol, figsize = (16, 10), sharex = True, sharey = True)\n",
    "fig.add_subplot(111, frameon=False)\n",
    "plt.xlabel(\"W\")\n",
    "plt.ylabel(\"SM5\")\n",
    "for sensor, ax in zip(sensor_names, axs.ravel()) : \n",
    "    dataset = inSitu_dfs_global_masked.loc[inSitu_dfs_global_masked['sensor_name'] == sensor,[\"W\", \"SM5\"]]\n",
    "    dataset = dataset.dropna()\n",
    "    X = dataset[\"W\"].values.reshape(-1,1)\n",
    "    y = dataset[\"SM5\"].values.reshape(-1,1)\n",
    "\n",
    "    lm = linear_model.LinearRegression()\n",
    "    lm.fit(X, y)\n",
    "    theta_d_reg = lm.predict([[0]]) # W = 0\n",
    "    theta_w_reg = lm.predict([[1]]) # W = 1\n",
    "    \n",
    "    inSitu_dfs_global_masked.loc[inSitu_dfs_global_masked['sensor_name'] == sensor,[\"theta_d_reg\"]] = theta_d_reg\n",
    "    inSitu_dfs_global_masked.loc[inSitu_dfs_global_masked['sensor_name'] == sensor,[\"theta_w_reg\"]] = theta_w_reg\n",
    "    \n",
    "    ax.plot(X, y, \"kx\")\n",
    "    ax.plot(X, lm.predict(X), color=\"blue\", linewidth=2)\n",
    "    ax.set_title(sensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6368f484",
   "metadata": {},
   "source": [
    "Then the $W$ values are converted to volumetric soil moisture units using $\\theta_d$, $\\theta_w$ in each scenario for further comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8223ad93",
   "metadata": {},
   "source": [
    "$$\\hat\\theta = W \\cdot (\\theta_w - \\theta_d) + \\theta_d$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15219cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inSitu_dfs_global_masked.loc[:,\"SM5_hat\"]     = inSitu_dfs_global_masked[\"W\"].values*(inSitu_dfs_global_masked['theta_w']     - inSitu_dfs_global_masked['theta_d'])     + inSitu_dfs_global_masked['theta_d']\n",
    "inSitu_dfs_global_masked.loc[:,\"SM5_hat_reg\"] = inSitu_dfs_global_masked[\"W\"].values*(inSitu_dfs_global_masked['theta_w_reg'] - inSitu_dfs_global_masked['theta_d_reg']) + inSitu_dfs_global_masked['theta_d_reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2078d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SM5_max = max(np.maximum(inSitu_dfs_global_masked.loc[:,\"SM5_hat_reg\"],\n",
    "#                         inSitu_dfs_global_masked.loc[:,\"SM5_hat\"],\n",
    "#                         inSitu_dfs_global_masked.loc[:,\"SM5\"]))\n",
    "\n",
    "inSitu_dfs_global_masked = inSitu_dfs_global_masked.dropna()\n",
    "mae_sc1 = mean_absolute_error(inSitu_dfs_global_masked[\"SM5\"],\n",
    "                              inSitu_dfs_global_masked[\"SM5_hat_reg\"])\n",
    "\n",
    "rmse_sc1 = mean_squared_error(inSitu_dfs_global_masked[\"SM5\"],\n",
    "                              inSitu_dfs_global_masked[\"SM5_hat_reg\"], squared=False)\n",
    "\n",
    "r_2_sc1 = r2_score(inSitu_dfs_global_masked[\"SM5\"],\n",
    "                   inSitu_dfs_global_masked[\"SM5_hat_reg\"])\n",
    "\n",
    "#----\n",
    "mae_sc2 = mean_absolute_error(inSitu_dfs_global_masked[\"SM5\"],\n",
    "                              inSitu_dfs_global_masked[\"SM5_hat\"])\n",
    "\n",
    "rmse_sc2 = mean_squared_error(inSitu_dfs_global_masked[\"SM5\"],\n",
    "                              inSitu_dfs_global_masked[\"SM5_hat\"], squared=False)\n",
    "\n",
    "r_2_sc2 = r2_score(inSitu_dfs_global_masked[\"SM5\"],\n",
    "                   inSitu_dfs_global_masked[\"SM5_hat\"])\n",
    "\n",
    "\n",
    "#SM5_max = max(np.maximum(inSitu_dfs_global_masked[\"SM5_hat_reg\"].copy(),\n",
    "#                         inSitu_dfs_global_masked[\"SM5_hat\"].copy(),\n",
    "#                         inSitu_dfs_global_masked[\"SM5\"].copy()))\n",
    "\n",
    "\n",
    "SM5_max = 40\n",
    "SM5_min = -1\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize = (18, 6))\n",
    "\n",
    "axs[0].title.set_text('theta_d, theta_w scenario1')\n",
    "axs[0].plot(\"SM5\",\"SM5_hat_reg\", 'bx',data = inSitu_dfs_global_masked)\n",
    "axs[0].axline((1, 1), slope=1, color = \"red\")\n",
    "axs[0].set_xlim([SM5_min, SM5_max])\n",
    "axs[0].set_ylim([SM5_min, SM5_max])           \n",
    "axs[0].text(0.5, 38, \"MAE = %.2f\"%mae_sc1, fontsize=12)\n",
    "axs[0].text(0.5, 36, \"RMSE = %.2f\"%rmse_sc1, fontsize=12)\n",
    "axs[0].text(0.5, 34, \"R² = %.2f\"%r_2_sc1, fontsize=12)\n",
    "axs[0].set(xlabel = 'Measured Soil Moisture (%)', ylabel = 'Estimated Soil Moisture (%)')\n",
    "\n",
    "axs[1].title.set_text('theta_d, theta_w scenario2')\n",
    "axs[1].plot(\"SM5\", \"SM5_hat\", 'bx', data = inSitu_dfs_global_masked)\n",
    "axs[1].axline((1, 1), slope=1, color = \"red\")\n",
    "axs[1].set_xlim([SM5_min, SM5_max])\n",
    "axs[1].set_ylim([SM5_min, SM5_max])  \n",
    "axs[1].text(0.5, 38, \"MAE = %.2f\"%mae_sc2, fontsize=12)\n",
    "axs[1].text(0.5, 36, \"RMSE = %.2f\"%rmse_sc2, fontsize=12)\n",
    "axs[1].text(0.5, 34, \"R² = %.2f\"%r_2_sc2, fontsize=12)\n",
    "axs[1].set(xlabel = 'Measured Soil Moisture (%)', ylabel = 'Estimated Soil Moisture (%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac0e0cd",
   "metadata": {},
   "source": [
    "$\\theta$ values in scenario 1 led to better results, but obviously some underfitted stations  are having a very negative effect on the overall performance of the adjustment, lets check it out :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854cdda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 4\n",
    "ncol = 3\n",
    "fig, axs = plt.subplots(nrow, ncol, figsize = (16, 16))\n",
    "fig.add_subplot(111, frameon=False)\n",
    "plt.xlabel('Measured Soil Moisture (%)')\n",
    "plt.ylabel('Estimated Soil Moisture (%)')\n",
    "for sensor, ax in zip(sensor_names, axs.ravel()) : \n",
    "    dataset = inSitu_dfs_global_masked.loc[inSitu_dfs_global_masked['sensor_name'] == sensor,[\"SM5_hat_reg\", \"SM5\"]]\n",
    "    ax.plot(dataset['SM5'], dataset['SM5_hat_reg'], \"bx\")\n",
    "    ax.set_xlim([SM5_min, SM5_max])\n",
    "    ax.set_ylim([SM5_min, SM5_max])\n",
    "    ax.axline((1, 1), slope=1, color = \"red\")\n",
    "    ax.set_title(sensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ea8f81",
   "metadata": {},
   "source": [
    " The sensor stations\n",
    " - **rg14vt19**\n",
    " - **rg34vt19**\n",
    "\n",
    "show a particularly unfavorable outcome, more research is needed to determine why. The model would benefit from the elimination of these variables at the risk of biasing it, in this analysis we will keep them.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006e55a5",
   "metadata": {},
   "source": [
    "<a id='section_7'></a>\n",
    "## 7 - $W$ maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca33973d",
   "metadata": {},
   "source": [
    "Finally the $W$ maps can be computed for the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2b6844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeW_by_px(ndvi, str_,\n",
    "                   i_d = edge_dry_intercept, \n",
    "                   s_d = edge_dry_slope,\n",
    "                   i_w = edge_wet_intercept,\n",
    "                   s_w = edge_wet_slope) : \n",
    "\n",
    "    STRd = STR_f(intercept = i_d,\n",
    "                 slope = s_d,\n",
    "                 ndvi = ndvi)\n",
    "    STRw = STR_f(intercept = i_w,\n",
    "                 slope = s_w,\n",
    "                 ndvi = ndvi)\n",
    "    w  = W(STRd, STRw, STR)\n",
    "    return(w)\n",
    "\n",
    "colors = [\"red\", \"darkorange\", \"yellow\", \"palegreen\", \"springgreen\", \"cyan\", \"blue\"]\n",
    "custom_cmap_w = LinearSegmentedColormap.from_list(\"mycmap\", colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d5e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "nsample = 5\n",
    "sample = random.sample(range(0, len(boa_files)), nsample)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42ba6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "boa_files = [f for f in os.listdir(BASE_DIR_BOA,) if os.path.isfile(os.path.join(BASE_DIR_BOA, f))]\n",
    "\n",
    "ncol = 2\n",
    "nrow = nsample \n",
    "boa_files_sample = [boa_files[i] for i in sample]\n",
    "fig, axes = plt.subplots(nrow, ncol, figsize=(15,3*nrow),\n",
    "                         sharex = True,\n",
    "                         sharey = True,\n",
    "                         constrained_layout = False)\n",
    "\n",
    "\n",
    "for idx, boa_fp in enumerate(boa_files_sample) : \n",
    "    \n",
    "    boa_fp = BASE_DIR_BOA + boa_fp\n",
    "    raster_date = S2_getDate(boa_fp)\n",
    "    scl_fp = S2_getIndex(\"./sen2r/out/SCL_res10/\", raster_date)\n",
    "    ndvi_fp = S2_getIndex(BASE_DIR_NDVI, raster_date)\n",
    "\n",
    "    scl = rioxarray.open_rasterio(scl_fp, masked=True)\n",
    "    scl = scl[0]\n",
    "    scl = scl.rename({'band':'scl',\n",
    "                       'x':'lat',\n",
    "                       'y':'long'})\n",
    "\n",
    "    ndvi = rioxarray.open_rasterio(ndvi_fp, masked=True)\n",
    "    ndvi = ndvi[0]\n",
    "    ndvi = ndvi.rename({'band':'ndvi',\n",
    "                        'x':'lat',\n",
    "                        'y':'long'})\n",
    "\n",
    "    boa  = rioxarray.open_rasterio(boa_fp, masked=True)\n",
    "    swir = boa[10]/10000\n",
    "    swir = swir.rename({'band':'STR',\n",
    "                        'x':'lat',\n",
    "                        'y':'long'})\n",
    "\n",
    "    STR  = ((1-swir)**2)/(2*swir)\n",
    "\n",
    "    w = computeW_by_px(ndvi, STR,\n",
    "                       i_d = edge_dry_intercept, \n",
    "                       s_d = edge_dry_slope,\n",
    "                       i_w = edge_wet_intercept,\n",
    "                       s_w = edge_wet_slope)\n",
    "\n",
    "    w_masked = w.where(\n",
    "                        (scl == 4) | # vegetation\n",
    "                        (scl == 5) | # not_vegetated\n",
    "                        (scl == 6)   # water\n",
    "                      ) \n",
    "\n",
    "    w.plot(ax=axes[idx,0], cmap = custom_cmap_w, vmin = 0, vmax = 1)\n",
    "    w_masked.plot(ax=axes[idx,1], cmap = custom_cmap_w, vmin = 0, vmax = 1)\n",
    "    axes[idx,0].title.set_text(\"%s unmasked\" % raster_date.date())\n",
    "    axes[idx,1].title.set_text(\"%s masked\" % raster_date.date())\n",
    "    \n",
    "    axes[idx,0].set_xticks([])\n",
    "    axes[idx,0].set_yticks([])\n",
    "    axes[idx,1].set_xticks([])\n",
    "    axes[idx,1].set_xticks([])\n",
    "    \n",
    "    axes[idx,0].axes.xaxis.set_visible(False)\n",
    "    axes[idx,0].axes.yaxis.set_visible(False)\n",
    "    axes[idx,1].axes.xaxis.set_visible(False)\n",
    "    axes[idx,1].axes.yaxis.set_visible(False)\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0.25)\n",
    "fig.suptitle(\"Walnut Gulch OPTRAM  - Normalized Soil Moisture Content (W)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d5128",
   "metadata": {},
   "source": [
    "Ending remarks : \n",
    "- Mainly the pixels are masked because of clouds, its obvious W is saturated in this structures.\n",
    "- The WB area is very homogenous, with a tipical low water content in the surface.\n",
    "- The aparent homogeneity in the maps, could be the consecuence of a overrepresentation of arid observations in the in situ measurements as it was discussed in [Data fusion](#section_5) and [Model parametrization](#section_6) sections.\n",
    "\n",
    "Its to be noted that the W maps **are not in volumetric units**, this is achieved by applying the regression model $SM5$ ~ $W$, but its not cover by the original paper. In a coming notebook several alternatives to obtain the volumetric $\\theta$ maps will be implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a832243",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "spatial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
